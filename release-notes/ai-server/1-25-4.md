# AI Server 1.25.4

Список изменений для версии 1.25.4, выпущенной в апреле 2025-го года.

## Умный OCR

### Поддержка многостраничного файла документов

Стала доступна обработка многостраничных документов в форматах PDF и TIFF. Функциональность упрощает работу с большим объемом данных и минимизирует ручной труд при подготовке RPA-проектов. 

Многостраничные файлы документов поддерживаются в запросах инференса, а также на странице **Тестирование** в веб-интерфейсе AI Server. Результат классификации/распознавания будет разбит по страницам.
  
**Важно**: многостраничные документы не поддерживаются в датасетах для обучения моделей.

![](<../../release-notes/resources/ai-server/1-25-4/testingresults-manypagespdf.png>)


### Просмотр логов ядра Data Science

На страницах всех типов процессов (обучение/инференс/авторазметка) появилась возможность просматривать логи ядра Data Science. Логи помогут лучше отслеживать состояние процесса на финальных этапах старта, например, когда система долго не отвечает; или в случае, если запущенный процесс аварийно завершился — в некоторых случаях только в логах ядра Data Science может содержаться причина завершения. 

Опция просмотра логов доступна в меню действий процесса. В случае, если логи содержат ошибки, вы можете скопировать список логов и отправить их разработчикам AI Server для получения консультации. 

![](<../../release-notes/resources/ai-server/1-25-4/processes-action-logs.png>)




### Улучшения

1. Повысили качество распознавания данных у модели неструктурированного документа (AnyText).
1. На странице **Тестирование** стало возможным просматривать качество распознавания данных:
   * если точность распознавания меньше 0,2, то значение подсветится красным;
   * если точность распознавания в диапазоне 0.2-0.79, то значение подсветится оранжевым;
   * если точность выше 0,8, то значение подсветится зеленым — это хороший уровень уверенности распознавания.
1. На странице **Тестирование** добавили возможность автоматически определять ориентацию изображения. В случае, если изображение имело в запросе неправильную ориентацию (например, было повернуто набок), то система автоматически это исправит для корректного изучения результатов распознавания. Чтобы использовать эту функцию, включите в шаблоне инференса параметр **Определение ориентации страницы перед распознаванием**. 
1. В форме импорта датасета появилась возможность выбирать, датасет какого типа вы хотите импортировать в проект. Для этого в форме импорта появился переключатель **Обучение / Тестовый**. Ранее возможно было импортировать только обучающий датасет.
1. На страницу **Данные** добавили уведомления, которые сообщают о статусе загрузки архива изображений. В случае, если загрузка завершилась ошибкой, вы поймете это по тексту всплывающего уведомления.


## AI Текст

### Распознавание текста на изображении документа

Расширили набор LLM-моделей в поставке AI Server. Теперь вам доступна **мультимодальная модель**, которая умеет работать как с текстовой информацией, так и с изображениями документов. 

Мультимодальная модель поддерживает все существующие навыки, а также дополнительный навык **OCR**. Если вы назначили модели навык **OCR**, то она сможет распознавать текст на изображении структурированного и неструктурированного документа, в том числе рукописный текст. 

Чтобы использовать мультимодальную модель в проекте типа **AI Текст > Задачи NLP**:
* Выберите базовую модель `base-LLM-04 (Vllm, multimodal)`, движок Vllm и укажите технические характеристики устройства, на котором работает сервер LLM;
* Запустите модель на целевой машине;
* Добавьте модели навык **OCR**:

  ![](<../../release-notes/resources/ai-server/1-25-4/ocr-skill.png>)

В запросе к мультимодальной модели с навыком OCR требуется обязательно указать файл изображения и, опционально, текст запроса. Например, в тексте запроса вы можете попросить модель найти значение какого-либо поля в паспорте.

**Допустимые форматы изображений**: JPG, JPEG, PNG. Ограничения по весу файла отсутствуют.

**Важно:** остальные навыки мультимодальной модели также работают с изображениями, но добавление изображения является для них опциональным. Другие LLM-модели с изображениями не работают.
  

### Улучшения

1. Все базовые LLM-модели из комплекта поставки теперь поддерживают работу на CPU и GPU:
   * *Мультимодальная модель поддерживает работу на GPU и CPU. Требования к CPU: 12 физических ядер, поддержка расширений AVX-512, оперативная память > 24 Гб.*
   * *Модели с движком Vllm стали запускаться на CPU.*
   * *Модели с движком Llama стали запускаться на GPU.*
1. Повысили стабильность запуска/остановки процессов Умного OCR и AI Текст.
1. Оптимизировали способ запуска моделей на движке Llama: теперь не требуется размещение файла docker-compose в системе.
1. Добавили мониторинг состояния процессов. Теперь, если агент недоступен, или физически процесс неожиданно остановился, это отразится на статусе процесса в веб-приложении.
1. Переименовали тип проекта **С использованием LLM** в тип **AI Текст** в соответствии с названием программного компонента.


## Исправленные ошибки 

1. Исправлены незначительные ошибки локализации в веб-интерфейсе на английском и русском языках. 
1. Исправлена ошибка, из-за которой некорректно отображался размер загруженного шаблона модели на странице **Настройки > Шаблоны моделей**.
1. Исправлена ошибка растрирования PDF.
1. Исправлены ошибки обновления статуса процесса всех типов.


## Библиотека Primo.AI.Server

С последними обновлениями библиотеки Primo.AI.Server вы можете ознакомиться по ссылкам:
* [Версия 1.0.11](https://docs.primo-rpa.ru/primo-rpa/release-notes/packages/windows/primo-ai-server/1.0.11) для Primo RPA Studio под **Windows**. 
* [Версия 1.0.11](https://docs.primo-rpa.ru/primo-rpa/release-notes/packages/linux/primo-ai-server/1-0-11) для Primo RPA Studio под **Linux**.
