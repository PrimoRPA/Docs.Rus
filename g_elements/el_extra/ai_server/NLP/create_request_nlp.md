# Создать запрос NLP

![](<../../../../.gitbook/assets1/windows_items/library/Primo.AI.Server.Elements.WFPrimoAICreateRequestNlp.png>)

Модель NLP (Natural Language Processing) обрабатывает входной текст на естественном языке и возвращает ответ, в зависимости от используемого навыка:
* Генерация — модель создает текст на основе начального ввода или заданного контекста.
* Суммаризация — модель кратко излагает текст с ацентом на указанные темы.
* Экстракция — модель извлекает из текста информацию по заданным ключам поиска.
* Классификация — модель отвечает на запрос, исходя из заранее определенного списка возможных ответов.

Элемент **Создать запрос NLP** отправляет запрос к NLP-модели в Primo RPA Server AI. В ответе сервер вернет идентификатор запроса, который сохранится в указанную переменную. Чтобы просмотреть результат обработки текста, используйте сохраненный идентификатор в элементе **Получить результат NLP**.

Как создать запрос с помощью элемента:
* укажите в свойствах элемента входной текст и ключи ответа;
* настройте маршрутизацию запроса к нужной модели и параметры ответа модели;
* укажите название переменной, которая будет хранить ответ сервера — автоматически присвоенный идентификатора запроса.




## Перед началом работы

1. Установите в Студии библиотеку [Primo.AI.Server](https://docs.primo-rpa.ru/primo-rpa/g_elements/el_extra/ai_server), поскольку данный элемент входит в состав библиотеки.
1. Найдите на панели элементов группу **AI > NLP** и перетащите элемент **Создать запрос NLP** в свой процесс.
1. Настройте параметры подключения к Server AI в контейнере **Сервер Primo.AI**.


## Свойства
Символ `*` указывает на обязательность заполнения свойства. Описание общих свойств см. в разделе [Свойства элемента](https://docs.primo-rpa.ru/primo-rpa/primo-studio/process/elements#svoistva-elementa).

**Обработка:**

1. **Текст\*** *[String]* — входной текст для обработки NLP-моделью. Пример: `"Текст договора"`.
1. **Ключи ответа** *[List\<String>]* — параметры, которые помогают модели сформировать наиболее релевантный ответ. Если ключей несколько, указывайте их через запятую. Ключи ответа зависят от NLP-навыка:
   * Для навыка экстракции укажите ключи поиска, по которым модель будет извлекать информацию из входного текста.  Пример: `"дата договора, стороны"`.
   * Для навыка генерации можно не указывать ключи или передать в них обязательные структурные элементы. Пример для генерации вакансии: `"Обязанности, Требования, Будет плюсом, Мы предлагаем"`.
   * Для навыка суммаризации укажите основные темы, которые необходимо передать при кратком изложении текста. Пример: `"основная идея, факты, выводы"`.
   * Для навыка классификации укажите классы, по которым будет осуществляться классификация текста. Пример для классификации заявок: `"1 линия техподдержки, 2 линия техподдержки, прочее"`.
1. **Длина ответа\*** *[Int32]* — максимальная длина ответа модели, которая измеряется в токенах. Для русского языка 1 слово ~ 1.5 токена. По умолчанию `256`.
1. **Ключ маршрутизации\*** *[String]* — ключ маршрутизации для вашего запроса. Каждый ключ ассоциирован с навыком NLP-модели и должен быть заранее создан на сервере Server AI. Пример ключа маршрутизации для навыка экстракции: `"nlp-extraction"`.
1. **Контекст** *[String]* — путь к файлу с контекстом (`.json`) на локальном диске. Файл контекста определяет поведение модели относительно запросов. По умолчанию с каждым ключом маршрутизации уже ассоциирован файл контекста на сервере. Используйте это свойство, если хотите заменить данный файл своим.
1. **Температура\*** *[Double]* — определяет вариативность ответа модели. Чем ниже температура, тем меньше вариативность в генерации. По умолчанию `0.1`.
1. **Min p\*** *[Double]* — определяет минимальный порог для выбора токенов из возможного диапазона, где `0` — любой токен, `1` — самый вероятный. Под токеном подразумевается единица текста: слово, символ и т.д. Чем выше порог, тем наиболее вероятные токены модель возьмет в ответ. По умолчанию `0.1`.


**Вывод:**
* **Результат** *[System.Guid]* — название переменной, в которую сохранится идентификатор запроса от сервера.

> *Если в ответе на запрос сервер вернул ошибку, она будет выведена в [консоль](https://docs.primo-rpa.ru/primo-rpa/primo-studio/process/debug#konsol) Студии.*
