# Настройка проекта для NLP-задач

Сразу после создания проекта вы автоматически попадете на страницу с настройкой проекта и тестированием навыков модели (две вкладки). Нет миллиона шагов, как в OCR.

(Скрин страницы с цифрами рабочих областей и поясняшками.)


Суть обработки естественного языка в том, чтобы получать на вход текст, который нейронка обрабатывает, находит ключи/классифицирует текст/или создает на его основе текст

## Вкладка Настройка

Представляет собой рабочую область с тремя частями: 
* конфигурация проекта — выбор базовой NLP-модели и технических характеристик целевой машины.
* целевые машины — настройка одной или нескольких машин, на которой будет запущена ваша NLP-модель.
* навыки NLP-моделей — выбор навыков NLP-модели по отношению к тексту на естественном языке.

### Конфигурация 1

Конфигурация состоит из основных и расширенных технических параметров.

Основные параметры:
1. **Выбор базовой модели** — выберите тип базовой модели, которая будет определять поведение модели нейросети. Доступные значения:
   * `llama3.1-8B (Vllm)` — базовая модель на сервере Vllm. Обрабатывает запросы быстрее. Работает не квантованная версия модели. Это более точная модель
   * `llama3.1-8B-GGUF (Llama)` — базовая модель на сервере Llama. Позволяет запускать большую языковую модель на низкотребовательном железе. Квантованная модель (?) с достаточно высоким квантованием. 

(на вкладке админа "Базовые модели" надо подробно описать, как создавать базовую NLP-модель)

1. **Ключ маршрутизации по умолчанию** — ключ по умолчанию для маршрутизации запросов. Ключ определяет, какой модели следует отправлять запрос для обработки. Ключ по умолчанию соответствует поведению модели без навыков. Модель ведет себя аналогично навыку "Генерация". Может быть не указан, если выбраны навыки?

Расширенные параметры:
1. **LLM-движок** — выберите тип движка. (хотели прикрутить к релизу связку движка и базовой модели - проверить потом). Доступные значения:
    * `Vllm` — сервер для базовой модели на Vllm.
    * `Llama` — сервер для базовой модели на Llama.
1. **Размер контекстного окна** — укажите объем текста, который модель рассматривает перед **генерацией** (и только?). По умолчанию `4096`.
1. **Адаптер** — не используется для NLP-задач, реализована для будущих версий. Пользовательская настройка для придания специфичности ответам базовой модели.
1. **Выбор устройства** — выберите тип устройства, который используется на целевой машине. Доступные значения:
    * `CPU` — по умолчанию.
    * `CUDA` —
   * **Кол-во используемых CPU** — параметр отображается, если выбрано устройство CPU. Укажите количество ядер CPU, которые будет использовать контейнер с выбранным движком для генерации ответов. По умолчанию `1` ядро.
   * **Кол-во используемых GPU** — параметр отображается, если выбрано устройство CUDA. Если модель не помещается в VRAM одной GPU, то следует использовать несколько видеокарт. По умолчанию `0`.
   * **Загруженность видеокарты** — параметр отображается, если выбрано устройство CUDA. Процент использования памяти видеокарты. Значение по умолчанию отсутствует.
   * **Кол-во памяти от хоста** — параметр отображается, если выбрано устройство CUDA. Если модель не помещается в VRAM одной GPU, часть слоев LLM оставляем на хосте.

Конфигурацию можно редактировать - только название - и удалить. После чего можно добавить новую конфигурацию.
Зачем меня имя конфигурации, например?

  
### Целевые машины

**Выбор целевой машины**:

Выберите одну или несколько целевых машин для запуска NLP-модели. Целевая машина должна соответствовать выбранному устройству в вашей конфигурации.

1. Нажмите **Добавить машину**.
1. Выберите название машины.
1. Переведите переключатель вправо, чтобы запустить NLP-модель на машине.
1. Убедитесь, что модель успешно запустилась — напротив статуса `Готова принимать запросы` должна стоять галочка.

Готово — теперь вы можете перейти к добавлению навыков NLP-модели.

{% hint style="warning" %}
Если в списке целевых машин нет нужного вам значения, убедитесь, что целевая машина была создана администратором на вкладке **Настройки > Целевые машины**.
{% endhint %}

**Остановка NLP-модели**:

Вам может понадобиться остановить NLP-модель, чтобы выключить машину или запустить на ней модель в другом проекте. Для этого просто переведите переключатель влево. Дождитесь, чтобы переключатель стал доступен для редактирования — это означает, что модель остановилась. 

### Навыки

По умолчанию, когда ни один навык для модели не указан, то она будет работать в режиме генерации текста. То есть даже в этом случае можно перейти на вкладку **Тестирование**, чтобы проверить, как модель будет создавать текст.

**Чтобы добавить другой навык**:
1. Нажмите **Добавить навык**.
1. Выберите доступный навык из списка:
   * `Классификация` — ответ на запрос из заранее определенного списка вариантов ответов. 
   * `Суммаризация` — краткое изложение текста с акцентом на определенные темы.
   * `Экстракция` — извлечение из текста информации по заданным ключам поиска.
   * `Генерация` — генерация текста по заданным параметрам.
1. Укажите ключ маршрутизации запросов для выбранного навыка. Для каждого навыка должен быть задан уникальный ключ.
1. После указания ключа автоматически отобразится **файл с контекстом** — это встроенный json-файл, который содержит ключи поиска, а также данные для ввода и вывода. Файл определяет поведение модели относительно будущих запросов. Вы можете:
   * отредактировать файл с контекстом;
   * скачать для просмотра;
   * заменить встроенный файл своим;
   * вернуть встроенный файл.

   (скрин с кнопками)

При необходимости добавьте другие навыки аналогично действиям выше.

{% hint style="warning" %}
Если в списке ключей маршрутизации нет нужного вам значения, убедитесь, что все необходимые ключи были созданы администратором на вкладке **Настройки > Ключи маршрутизации**.
{% endhint %}



## Вкладка Тестирование

Предназначена для тестирования указанных навыков NLP-модели. Здесь вы можете быстро проверить, как работает тот или иной навык и отладить ваши настройки при необходимости. Фактически эта вкладка показывает, что получит робот при отправке запроса на целевую машину или при использовании API-запросов. Это не способ эксплуатации модели.

Поведение в выбранном ключе маршрутизации зависит от файла с контекстом. Тестирование позволяет изменять файл с контекстом, чтобы просмотреть, как отличается поведение модели. Когда все в порядке, мы фиксируем это положение и уже дальше роботы по апи обращаются, и мы понимаем, что результат будет ожидаемым.

**Изменение файла контекста в тестировании изменит файл и для навыка на вкладке "Настройки"?** проверить

Рабочая область состоит из двух областей:
* Запрос — содержит параметры запроса.
* Ответ — ответ на запрос от NLP-модели.

### Запрос

1. **Текст для обработки\*** — входной текст для обработки NLP-моделью. На текущий момент отсутствует возможность прикреплять файл документа. Ограничение на количество символов отсутствует и определяется настройками сервера (что имеется в виду, где именно).
1. **Ключи ответа\*** — если был выбран навык Генерация, поставьте в этом поле пробел. Если ключей несколько, указывайте их через запятую.
1. **Ключ маршрутизации\*** — выберите ключ маршрутизации, указанный для навыка, который вы хотите протестировать.
1. **Длина ответа\*** — по умолчанию `256`. в чем измеряется...

Расширенные параметры:
1. **Температура** — влияет на вариативность ответа. По умолчанию `0.1`. Максимальное значение - ?.
1. **min_p** — ограничивает что?(сэмплирование?)... чтобы не выбирать все варианты, даже маловероятные. По умолчанию `0.1`. Максимальное значение - 1.

   каждый следующий токен имеет некую вероятность появления. Она может быть 30%, 90%. И когда явная информация - модель ее найдет. А если, например, "расскажи мне стих", то будет много вероятностей. Параметр определяет, какой уровень отсечки - от самого высоко вероятного токена до самого низкого модель будет брать. Выбирает, какие варианты нужно отсеять в ответе: наиболее вероятные или менее. Если поставить 0.0., то вообще почти все вытащит.

   Если мы хотим увеличить вариативность ответов, то ставим температуру 1, а min_p 0.0.

   Если снизить галлюцинации, то температуру снижаем до 0.1, а min_p повышаем.

   По опыту самые оптимальные варианты - 0.1 для каждого параметра.
    
1. **Файл с контекстом (.json)** — возможность переопределить контекст для ключа маршрутизации.

В завершение нажмите **Отправить**, чтобы получить ответ от модели.


### Ответ

Область для получения ответа от NLP-модели. Ответ можно скопировать и обновить. 

Ошибки будут подсвечены - появится всплывашка. Добавить пример.

Ответ может быть выдан в виде текста - например, для навыка генерации. Или в виде json (структурированной информции) - например, для навыка экстракции, где будет извлекаться информация по ключам ответа.

Если по указанному ключу модель нашла несколько значений, она укажет их в значениях ключа.

### Пример тестирования навыка Генерация

Например, "напиши стих".

### Пример тестирования навыка Экстракция

Задача - извлечь какие-то данные из текста.

Например, ввести договор и указать ключи ответа - по которым из json вытягивается информация. Реквизиты, штрафные санкции, срок действия договора, стороны.

Для экстракции температуру и тд лучше выставлять минимальные, чтобы ограничить вариативность. 

### Пример тестирования навыка Суммаризация


### Пример тестирования навыка Классификация


