# Настройка и запуск модели

[Создайте](https://docs.primo-rpa.ru/primo-rpa/primo-rpa-ai-server/user/projects/operations-with-project#sozdat-proekt) проект с типом **NLP-задачи**. 

После создания проекта автоматически откроется страница настройки. Цель выполнения настроек — запустить сервер с большой языковой моделью, которая готова обрабатывать NLP-запросы. 

Если вы не готовы сразу указывать настройки, то можете перейти на эту страницу позже — просто выберите на главной странице карточку вашего проекта.

![](</primo-ai/resources/user/nlpproject/nlp_config.png>) 

На рисунке отмечены:
* `1` — Область технических настроек для запуска модели. 
* `2` — Область, где выбираются целевые машины для запуска модели.
* `3` — Область выбора навыков, которыми должна обладать модель. Навыки определяют, какие NLP-задачи будет способна решать модель.
* `4` — Кнопка создания новой конфигурации. NLP-проекты могут поддерживать несколько моделей с различными конфигурациями.
* `5` — Меню управления конфигурацией. Каждую конфигурацию можно переименовать, дублировать или удалить.
* `6` — Вкладка [**Тестирование**](https://docs.primo-rpa.ru/primo-rpa/primo-rpa-ai-server/user/rabota-s-tipom-proekta-nlp-zadachi/testing), которая позволяет отправлять тестовые запросы на целевую машину с запущенной моделью. На вкладке можно просматривать ответы и корректировать поведение модели при необходимости. Вкладка недоступна, пока не выполнены настройки в областях 1-2.


## Основные параметры 

Модель конфигурируется на основе базовой модели и настроек её LLM-движка: 

* **Базовая модель** — это предобученная на большом количестве текстов модель, которая может понимать и генерировать текст на естественном языке. Базовые модели входят в поставку AI Server, а также могут быть созданы дополнительно администратором сервиса в разделе [Шаблоны моделей](https://docs.primo-rpa.ru/primo-rpa/primo-rpa-ai-server/admin/model-templates). Выбор базовой модели зависит от аппаратных характеристик целевой машины и сценариев использования модели. Чтобы правильно выбрать базовую модель, рекомендуется протестировать обработку конкретных запросов на разных типах, поскольку для разных сценариев использования может быть предпочтительна та или иная модель.
* **LLM-движок** — это LLM-ядро, которое обеспечивают работу модели на целевой машине. Выбор ядра прямым образом влияет на выбор базовой модели. 


**Основные параметры конфигурации**:

1. **Выбор базовой модели** — выберите тип базовой модели из выпадающего списка. По умолчанию доступны следующие типы:
   * `base-LLM-01 (Vllm)` — базовая модель, которая работает на движке Vllm. Она способна быстро и точно обрабатывать запросы, но более требовательна к аппаратным характеристикам целевой машины.
   * `base-LLM-02 (Llama)` — базовая модель, которая работает на движке Llama и позволяет запускать LLM-модель на низкотребовательной целевой машине с CPU.
   * `base-LLM-03 (Vllm)` — базовая модель, которая работает на движке Vllm. 

1. **Ключ маршрутизации по умолчанию** — данный ключ используется для маршрутизации запросов к модели без выбранных навыков, которая работает только в режиме генерации текстов.

**Расширенные параметры:**

1. **LLM-движок** — тип движка, который ассоциирован с базовой моделью. Доступные значения:
    * `Vllm` — сервер для базовой модели на Vllm. Подходит для высокопроизводительных вычислений на графической карте.
    * `Llama` — сервер для базовой модели на Llama. Лучше работает на CPU, поскольку отличается меньшим временем генерации первого токена. Llama на текущий момент не поддерживается для GPU.
1. **Размер контекстного окна** — предельное количество токенов (текстовых единиц), которые могут быть указаны во входном тексте для обработки. Одно слово на русском языке ~ 2 токена. По умолчанию `4096`.
1. **Адаптер** — пропустите этот параметр, он не поддерживается для NLP-задач.
1. **Выбор устройства** — тип устройства, который используется на целевой машине с сервером LLM. Доступные значения:
    * `CPU` — значение по умолчанию. Центральный процессор, выполняющий основные операции и управляющий работой компьютера.
    * `CUDA` — архитектура CUDA позволяет использовать графический процессор (GPU) от NVIDIA для повышения производительности параллельных вычислений. CUDA представляет собой набор инструментов и библиотек для работы с графическим процессором.

   Если вы выбрали `CPU`, установите:
   * **Кол-во используемых CPU** — количество ядер CPU, которые будет использовать контейнер с выбранным движком для генерации ответов. 

   Если вы выбрали `CUDA`, установите:
   * **Кол-во используемых GPU** — количество видеокарт. Если модель не помещается в VRAM одной GPU, используйте несколько видеокарт. 
   * **Загруженность видеокарты** — процент использования памяти видеокарты. 
   * **Кол-во памяти от хоста** — если модель не помещается в VRAM одной GPU, оставьте часть слоев LLM на хосте.

  
## Целевые машины

Целевая машина — логическая сущность в AI Server, которая представляет собой физическую или виртуальную машину (или группу машин) с агентом. Агент управляет моделью: запускает, настраивает, останавливает модель, отправляет запросы от сервера. 

В проект можно добавить только включенную и доступную целевую машину. Чтобы горизонтально масштабировать процесс, вы можете запустить модель сразу на нескольких машинах. При этом агент каждой целевой машины должен быть лицензирован. 

{% hint style="warning" %}
Если в списке целевых машин нет нужного значения, убедитесь, что машина была создана администратором на странице [**Настройки > Целевые машины**](https://docs.primo-rpa.ru/primo-rpa/primo-rpa-ai-server/admin/machines), а также включена и доступна.
{% endhint %}

**Как запустить модель:**

1. Нажмите **Добавить машину**.
1. Выберите из выпадающего списка название машины. Добавленная машина будет ожидать запуска модели.
1. Чтобы запустить модель, переведите переключатель вправо.

   ![](</primo-ai/resources/user/nlpproject/run_llm_model.png>)  
  
   Начнется автоматический процесс запуска — он займет некоторое время.

1. Дождитесь, когда напротив всех стадий запуска будут проставлены галочки — это означает, что модель успешно запустилась и готова к работе.

   ![](</primo-ai/resources/user/nlpproject/nlp_statuses_model.png>) 

   Если вы обновите страницу, то вместо стадий запуска увидите только один статус — `Готова принимать запросы`.

Теперь вы можете перейти к добавлению навыков модели.


**Ошибка при запуске модели**:

Если процесс запуска завершился ошибкой, то вместо статуса `Готова принимать запросы`, вы увидите индикатор ошибки. Наведите курсор на индикатор, чтобы увидеть текст ошибки.

**Как остановить модель**:

Вам может понадобиться остановить LLM-модель, чтобы выключить машину или запустить на ней модель в другом проекте. Для этого просто переведите переключатель влево. Дождитесь, чтобы переключатель стал доступен для редактирования — это означает, что модель остановилась. 

**Как удалить целевую машину**:

Чтобы удалить целевую машину из проекта, нажмите на меню рядом с именем машины и выберите **Удалить**.


## Навыки

Навык — это способность языковой модели выполнять определенные задачи, связанные с обработкой и созданием текста. Модель без навыков способна только создавать тексты — это поведение соответствует навыку *Генерация*. 

Одной модели можно назначить несколько навыков. При указании навыка потребуется выбрать ключ маршрутизации — уникальный ключ, с помощью которого сервер выбирает модель и навык для обработки поступившего запроса. Вы можете дублировать навыки в одной конфигурации, но ключи маршрутизации повторяться не могут.

После выбора ключа:
* Отобразится поле **Системный промпт** — промпт позволяет на системном уровне определить поведение модели. Для каждого навыка предзадан промт по умолчанию, в котором прописана роль, задачи и формат ответа модели. Вы можете переопределить промт на свое усмотрение или, при необходимости, вернуться к предустановленному тексту промта.
* Автоматически загрузится файл контекста — предустановленный json-файл, который также помогает определить поведение модели за счет предоставленного контекста с примерами запросов и ответов. Контекст помогает генерировать более релевантные и точные ответы. Вы можете заменять файл контекста собственным файлом или, при необходимости, вернуться к предустановленному файлу контекста.

### Как добавить навык

1. Выберите **Добавить навык**.
1. Выберите навык из списка:
   * `Классификация` — ответ на запрос из заранее определенного списка вариантов ответов. 
   * `Суммаризация` — краткое изложение текста с акцентом на определенные темы.
   * `Экстракция` — извлечение из текста информации по заданным ключам поиска.
   * `Генерация` — создание нового текста по заданным параметрам. 
1. Выберите ключ маршрутизации запросов. 
1. После выбора ключа автоматически отобразится **файл с контекстом (.json)**. Вы можете:
   * скачать файл для просмотра;
   * заменить файл по умолчанию своим файлом;
   * отредактировать свой файл с контекстом, который вы загрузили вместо файла по умолчанию;
   * восстановить файл по умолчанию.

   ![](</primo-ai/resources/user/nlpproject/model_skill.png>)  

1. В поле **Системный промпт** отображается инструкция, определяющая базовое поведение модели. При нажатии **карандаша** вы сможете просмотреть текст инструкции и изменить его при необходимости.

   Если текст был изменен, но вы захотели вернуться к промпту по умолчанию, то нажмите иконку ![](</primo-ai/resources/user/nlpproject/system-prompt-default.png>).

   ![](</primo-ai/resources/user/nlpproject/system-prompt.png>)  

Дополнительные навыки добавляются аналогично действиям выше.

{% hint style="warning" %}
Если в списке ключей маршрутизации нет нужного вам значения, убедитесь, что все необходимые ключи были созданы администратором на вкладке [**Настройки > Ключи маршрутизации**](https://docs.primo-rpa.ru/primo-rpa/primo-rpa-ai-server/admin/routing-keys).
{% endhint %}


## Что дальше

Перейдите на вкладку [Тестирование](https://docs.primo-rpa.ru/primo-rpa/primo-rpa-ai-server/user/rabota-s-tipom-proekta-nlp-zadachi/testing), чтобы проверить качество ответов модели.

