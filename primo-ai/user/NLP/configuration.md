# Настройка и запуск модели

[Создайте](https://docs.primo-rpa.ru/primo-rpa/primo-rpa-ai-server/user/projects/operations-with-project#sozdat-proekt) проект с типом **NLP-задачи**. 

После создания проекта автоматически откроется страница настройки. Чтобы перейти на нее позже, просто выберите на главной странице карточку вашего проекта.

Цель выполнения настроек — запустить сервер с большой языковой моделью, которая готова обрабатывать NLP-запросы. 

![](</primo-ai/resources/user/nlpproject/nlp_config.png>) 

На рисунке отмечены:
* `1` — Область базовых настроек модели. Это обязательный шаг — каждую модель следует сконфигурировать до запуска на целевой машине. 
* `2` — Область для выбора целевых машин, на которых следует запускать модель. 
* `3` — Область для выбора навыков, которыми должна обладать модель. Навыки определяют, какие NLP-задачи будет способна решать модель.
* `4` — Кнопка добавления новой конфигурации. NLP-проекты могут поддерживать несколько моделей с различными конфигурациями.
* `5` — Меню управления конфигурацией. Каждую конфигурацию можно переименовать или удалить.
* `6` — Вкладка [**Тестирование**](https://docs.primo-rpa.ru/primo-rpa/primo-rpa-ai-server/user/rabota-s-tipom-proekta-nlp-zadachi/testing) позволяет отправлять тестовые запросы на целевую машину с запущенной моделью, просматривать ответы и корректировать поведение модели при необходимости. Вкладка недоступна, пока не выполнены настройки в областях 1-2.


## Основные параметры 

Модель конфигурируется на основе базовой модели и настроек ее LLM-движка. 

Базовая модель — это предобученная на большом количестве текстов модель, которая может понимать и генерировать текст на естественном языке. Базовые модели входят в поставку AI Server, а также могут быть созданы дополнительно администратором сервиса в разделе **Шаблоны моделей**. Выбор базовой модели зависит от аппаратных характеристик целевой машины и сценариев использования модели. Чтобы правильно выбрать базовую модель, рекомендуется протестировать обработку конкретных запросов на разных типах, поскольку для разных сценариев использования может быть предпочтительна та или иная модель.

LLM-движок — это LLM-ядро, которое обеспечивают работу модели на целевой машине. Выбор ядра прямым образом влияет на выбор базовой модели. 


**Заполните параметры**:

1. **Выбор базовой модели** — выберите тип базовой модели из выпадающего списка. По умолчанию доступны следующие типы:
   * `llama3.1-8B (Vllm)` — базовая модель, которая разработана компанией Meta и работает на движке Vllm. Постфикс `8B` указывает 8 миллиардов параметров модели, которые используются для качественной обработки сложных запросов. Этот тип базовой модели обрабатывает запросы быстрее и точнее, но более требователен к аппаратным характеристикам целевой машины.
   * `llama3.1-8B-GGUF (Llama)` — базовая модель на движке Llama. Позволяет запускать большую языковую модель на низкотребовательной целевой машине с CPU.
   * `qwen2.5-7B (Vllm)` — базовая модель, которая  разработана компанией Qwen и работает на движке Vllm. Постфикс `7B` указывает на 7 миллиардов параметров модели.

1. **Ключ маршрутизации по умолчанию** — данный ключ используется для маршрутизации запросов к модели без выбранных навыков, которая работает только в режиме генерации текстов.

**Укажите расширенные параметры:**

1. **LLM-движок** — тип движка, который ассоциирован с базовой моделью. Доступные значения:
    * `Vllm` — сервер для базовой модели на Vllm. Подходит для высокопроизводительных вычислений на графической карте.
    * `Llama` — сервер для базовой модели на Llama. Лучше работает на CPU, поскольку отличается меньшим временем генерации первого токена. Llama на текущий момент не поддерживается для GPU.
1. **Размер контекстного окна** — предельное количество токенов (текстовых единиц), которые могут быть указаны во входном тексте для обработки. Одно слово на русском языке ~ 2 токена. По умолчанию `4096`.
1. **Адаптер** — пропустите этот параметр, он не поддерживается для NLP-задач.
1. **Выбор устройства** — тип устройства, который используется на целевой машине с сервером LLM. Доступные значения:
    * `CPU` — значение по умолчанию. Центральный процессор, выполняющий основные операции и управляющий работой компьютера.
    * `CUDA` — архитектура CUDA позволяет использовать графический процессор (GPU) от NVIDIA для повышения производительности параллельных вычислений. CUDA представляет собой набор инструментов и библиотек для работы с графическим процессором.

   Если вы выбрали `CPU`, установите:
   * **Кол-во используемых CPU** — количество ядер CPU, которые будет использовать контейнер с выбранным движком для генерации ответов. 

   Если вы выбрали `CUDA`, установите:
   * **Кол-во используемых GPU** — количество видеокарт. Если модель не помещается в VRAM одной GPU, используйте несколько видеокарт. 
   * **Загруженность видеокарты** — процент использования памяти видеокарты. 
   * **Кол-во памяти от хоста** — если модель не помещается в VRAM одной GPU, оставьте часть слоев LLM на хосте.

  
## Целевые машины

Целевая машина — логическая сущность в Server AI, которая представляет собой физическую или виртуальную машину (или группу машин) с агентом. Агент управляет моделью: запускает, настраивает, останавливает модель, отправляет запросы от сервера. 

В проект можно добавить только включенную и доступную целевую машину. Чтобы горизонтально масштабировать процесс, вы можете запустить модель сразу на нескольких машинах. При этом агент каждой целевой машины должен быть лицензирован. 

{% hint style="warning" %}
Если в списке целевых машин нет нужного значения, убедитесь, что машина была создана администратором на странице [**Настройки > Целевые машины**](https://docs.primo-rpa.ru/primo-rpa/primo-rpa-ai-server/admin/machines), а также включена и доступна.
{% endhint %}

**Как запустить модель:**

1. Нажмите **Добавить машину**.
1. Выберите из выпадающего списка название машины. Добавленная машина будет ожидать запуска модели.
1. Чтобы запустить модель, переведите переключатель вправо.

   ![](</primo-ai/resources/user/nlpproject/run_llm_model.png>)  
  
   Начнется автоматический процесс запуска — он займет некоторое время.

1. Дождитесь, когда напротив всех стадий запуска будут проставлены галочки — это означает, что модель успешно запустилась и готова к работе.

   ![](</primo-ai/resources/user/nlpproject/nlp_statuses_model.png>) 

   Если вы обновите страницу, то вместо стадий запуска увидите только один статус — `Готова принимать запросы`.

Теперь вы можете перейти к добавлению навыков модели.


**Ошибка при запуске модели**:

Если процесс запуска завершился ошибкой, то вместо статуса `Готова принимать запросы`, вы увидите индикатор ошибки. Наведите курсор на индикатор, чтобы увидеть текст ошибки.

**Как остановить модель**:

Вам может понадобиться остановить LLM-модель, чтобы выключить машину или запустить на ней модель в другом проекте. Для этого просто переведите переключатель влево. Дождитесь, чтобы переключатель стал доступен для редактирования — это означает, что модель остановилась. 

**Как удалить целевую машину**:

Чтобы удалить целевую машину из проекта, нажмите на меню рядом с именем машины и выберите **Удалить**.


## Навыки

Навык — это способность языковой модели выполнять определенные задачи, связанные с обработкой и созданием текста. Модель без навыков способна только создавать тексты — это поведение соответствует навыку *Генерация*. 

Одной модели можно назначить несколько навыков. При указании навыка потребуется выбрать ключ маршрутизации — уникальный ключ, с помощью которого сервер выбирает модель и навык для обработки поступившего запроса. Вы можете дублировать навыки в одной конфигурации, но ключи маршрутизации повторяться не могут.

После выбора ключа в конфигурацию автоматически загрузится файл контекста — предустановленный json-файл, который определяет поведение модели. Файл контекста помогает улучшать качество ответов модели и генерировать более релевантные и точные ответы. 

Вы можете заменять файл контекста собственным файлом — и таким образом, влиять на поведение модели. При необходимости можно вернуться к предустановленному файлу контекста.

### Как добавить навык

1. Выберите **Добавить навык**.
1. Выберите навык из списка:
   * `Классификация` — ответ на запрос из заранее определенного списка вариантов ответов. 
   * `Суммаризация` — краткое изложение текста с акцентом на определенные темы.
   * `Экстракция` — извлечение из текста информации по заданным ключам поиска.
   * `Генерация` — создание нового текста по заданным параметрам. 
1. Выберите ключ маршрутизации запросов. 
1. После выбора ключа автоматически отобразится **файл с контекстом (.json)**. Вы можете:
   * скачать файл для просмотра;
   * заменить файл по умолчанию своим файлом;
   * отредактировать свой файл с контекстом, который вы загрузили вместо файла по умолчанию;
   * восстановить файл по умолчанию.

   ![](</primo-ai/resources/user/nlpproject/model_skill.png>)  


Дополнительные навыки добавляются аналогично действиям выше.

{% hint style="warning" %}
Если в списке ключей маршрутизации нет нужного вам значения, убедитесь, что все необходимые ключи были созданы администратором на вкладке [**Настройки > Ключи маршрутизации**](https://docs.primo-rpa.ru/primo-rpa/primo-rpa-ai-server/admin/routing-keys).
{% endhint %}


## Что дальше

Перейдите на вкладку [Тестирование](https://docs.primo-rpa.ru/primo-rpa/primo-rpa-ai-server/user/rabota-s-tipom-proekta-nlp-zadachi/testing), чтобы проверить качество ответов модели, или сразу используйте модель посредством роботов или API.

