# Тестирование

## Вкладка Тестирование

(Страница тестирования доступна при выполнении следующих условий: Заполнены основные параметры, Добавлена машина и на этой машине висит статус "Готова принимать запросы". Если после выполнения условий, удалить машину или остановить на ней процесс, то вкладка тестирования вновь становится недоступной)

Предназначена для тестирования указанных навыков NLP-модели. Здесь вы можете быстро проверить, как работает тот или иной навык и отладить ваши настройки при необходимости. Фактически эта вкладка показывает, что получит робот при отправке запроса на целевую машину или при использовании API-запросов. Это не способ эксплуатации модели.

Поведение в выбранном ключе маршрутизации зависит от файла с контекстом. Тестирование позволяет изменять файл с контекстом, чтобы просмотреть, как отличается поведение модели. Когда все в порядке, мы фиксируем это положение и уже дальше роботы по апи обращаются, и мы понимаем, что результат будет ожидаемым.

**Изменение файла контекста в тестировании изменит файл и для навыка на вкладке "Настройки"?** проверить

Рабочая область состоит из двух областей:
* Запрос — содержит параметры запроса.
* Ответ — ответ на запрос от NLP-модели.

### Запрос

1. **Текст для обработки\*** — входной текст для обработки NLP-моделью. На текущий момент отсутствует возможность прикреплять файл документа. Ограничение на количество символов отсутствует и определяется настройками сервера (что имеется в виду, где именно).
1. **Ключи ответа\*** — если ключей несколько, указывайте их через запятую (без ошибок):
   * для генерации - если был выбран навык Генерация, поставьте в этом поле пробел.
   * для экстракции - ключи поиска для
   * для суммаризации - ?
   * для классификации - 
1. **Ключ маршрутизации\*** — выберите ключ маршрутизации, указанный для навыка, который вы хотите протестировать.
1. **Длина ответа\*** — максимальная длина ответа модели в токенах. Для русского языка 1 слово ~ 1.5 токена. По умолчанию `256`. 


Расширенные параметры:
1. **Температура** — влияет на вариативность ответа. По умолчанию `0.1`. Максимальное значение - ?.
1. **min_p** — ограничивает что?(сэмплирование?)... чтобы не выбирать все варианты, даже маловероятные. По умолчанию `0.1`. Максимальное значение - 1.

   каждый следующий токен имеет некую вероятность появления. Она может быть 30%, 90%. И когда явная информация - модель ее найдет. А если, например, "расскажи мне стих", то будет много вероятностей. Параметр определяет, какой уровень отсечки - от самого высоко вероятного токена до самого низкого модель будет брать. Выбирает, какие варианты нужно отсеять в ответе: наиболее вероятные или менее. Если поставить 0.0., то вообще почти все вытащит.

   Если мы хотим увеличить вариативность ответов, то ставим температуру 1, а min_p 0.0.

   Если снизить галлюцинации, то температуру снижаем до 0.1, а min_p повышаем.

   По опыту самые оптимальные варианты - 0.1 для каждого параметра.
    
1. **Файл с контекстом (.json)** — возможность переопределить контекст для ключа маршрутизации.

В завершение нажмите **Отправить**, чтобы получить ответ от модели.


### Ответ

Область для получения ответа от NLP-модели. Ответ можно скопировать и обновить. 

Ошибки будут подсвечены - появится всплывашка. Добавить пример.

Ответ может быть выдан в виде текста - например, для навыка генерации. Или в виде json (структурированной информции) - например, для навыка экстракции, где будет извлекаться информация по ключам ответа.

Если по указанному ключу модель нашла несколько значений, она укажет их в значениях ключа.






Как уменьшить количество ошибок в ответах модели?

В ситуациях, когда вам требуется более точный и логичный ответ, используйте следующие способы:
Прописывайте ключи ответа, а также лучше формулируйте запрос при использовании навыка генерации. Чем больше подробностей, тем лучше модель поймет, что от неё хотят. 
Редактируйте файлы контекста под задачи своей организации. Когда модель отвечает с опорой на составленный контекст, она может использовать эту информацию для более точных ответов. Укажите в файле контекста как можно больше информации, которая ей может пригодится.
Ограничьте свободу модели. Отрегулируйте параметры температуры и минимального порога так, чтобы уменьшить шанс неправильного или выдуманного ответа. 

Следует понимать, что даже при этих условиях полностью исключить неправильные ответы модели не получится. 










### Пример тестирования навыка Генерация

---
Экстракция чем-то повторяет умный OCR, но там есть ограничение - мы должны натренировать модель, а документ должен быть заранее определенной формы. А эни док - как раз из него будет выходить текст из скана в LLM, чтобы по ключам вытаскивать структ-ю инфу.
Скан документа - в умный осr в эни док (для неструктурированной инфы), выход - сырой текст в NLP-модель.

Также работу можно настроить: модель сначала классифицирует (NLP), потом вытягивает (экстракция).
---

Например, создавать вакансию или вопросы для интервью.

### Пример тестирования навыка Экстракция

Задача - извлечь какие-то данные из текста. Большие запросы от структур, где надо вытащить, от какого клиента запрос, номер счета и т.д.

На входе - неструктурированный текст, на выходе - структурированный.

Например, ввести договор и указать ключи ответа - по которым из json вытягивается информация. Реквизиты, штрафные санкции, срок действия договора, стороны.

Для экстракции температуру и тд лучше выставлять минимальные, чтобы ограничить вариативность. 

### Пример тестирования навыка Суммаризация

в запросе - текст договора

например, в ключе прописать - о чем договор





### Пример тестирования навыка Классификация

Разбор корпоративного ящика. Есть 20 адресатов, например. 

например много писем, где нам надо понять, где спам, а где нет

или для нужд техподдержки: 
в файле контекста в инпуте надо прописать, например, "сломался принтер"
ключи - разные варианты
в выводе, например "системный админ"

в файле определяется маршрутизация по ключам - кто за что отвечает


