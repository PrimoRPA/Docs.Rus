# Перед установкой

В этом разделе приведены общие сведения о программных компонентах для группы целевых машин с *NLP* и системные требования к таким машинам.

## Общие сведения

Компоненты Primo.AI.Api и их связи с NLP-компонентом "AI Текст" приведены на схеме ниже:

![Компоненты Primo.AI.Api и группы целевых машин NLP](<../../../../.gitbook/assets1/primo-ai/install/nlp-components-and-machines-scheme.png>)

**Группа целевых машин NLP** - набор из 4 сервисов, обеспечивающих работу LLM-модели в рамках NLP-задач. Состоит из **Logics-сервера** с агентом и **LLM-ядра** с агентом.

**Агент Logics-сервера** – self-hosted веб-приложение, REST API. Управляет Logics-сервером, а также агентом LLM-ядра. Лицензируется (требует 1 лицензии на Агента Primo RPA AI Server). Выполнено как NET8-приложение, которое размещено на той же физической или виртуальной машине-хосте, что и контейнер **Logics-сервера**. 

**Logics-сервер** – python-приложение, логическая обвязка вокруг LLM-ядра. Размещено в отдельном docker-контейнере на той же физической или виртуальной машине-хосте, что и его **агент Logics-сервера**.

**Агент LLM-ядра** – self-hosted веб-приложение, REST API. Управляет LLM-ядром. Выполнено как NET8-приложение, которое размещено на той же физической или виртуальной машине-хосте, что и контейнер **LLM-ядра**. 

**LLM-ядро** – python-приложение, обеспечивающее работу LLM-модели. Тип ядра определяется полем **Движок** в Портале. Размещено в отдельном docker-контейнере на той же физической или виртуальной машине-хосте, что и **агент LLM-ядра**.

Группа целевых машин NLP может представлять из себя как единственную физическую или виртуальную машину с 2 docker-контейнерами и 2 агентами, так и располагаться на 2 разных машинах. При этом наибольшие требования к производительности предъявляет машина с LLM-ядром.
Не рекомендуется размещать на машине с LLM-ядром другие ресурсоёмкие приложения. 
Групп целевых машин NLP может быть много. Все группы целевых машин NLP должны быть настроены одинаково, и на каждой целевой машине должен быть развернут агент. Версии ОС на целевых машинах могут отличаться.

Порт `44392`, указанный на схеме выше, используется при настройке конфигурационных файлов агента и открытия портов на файерволе (в том числе аппаратном в сети организации). 

Для настройки группы целевых машин NLP нужна чистая машина с ОС Linux (обязательно с последними обновлениями). На машину необходимо скопировать папку с комплектом поставки. Это может быть любая папка, но для определенности пусть будет папка `/srv/samba/shared/install`*.

Для настройки группы целевых машин NLP требуется последовательно выполнить все шаги настоящего руководства.

> \**Сетевая папка, доступная с машины, на которой размещен комплект поставки.* 



## Системные требования
Для группы целевых машин NLP следует использовать рабочие станции под управлением Astra Linux, к которой предъявляются требования из таблицы ниже.

| Параметр        | Требование машины с Logics-сервером    | Требование машины с LLM-ядром          	       | 
| --------------- | -------------------------------------- |-------------------------------------------------| 
| CPU             | 4 физических ядра / 8 виртуальных ядер | 4 физических ядра / 8 виртуальных ядер 	    	 | 
| RAM             | 8 Гб	                                 | 32 Гб	                                	    	 |  
| HDD             | 50 Гб (OS + Data)	                     | 250 Гб (OS + Data)	                    		     |
| GPU             | не требуется                           | Рекомендуется (см. варианты установки LLM-ядра) |


## Что дальше

Выполните установку docker на каждую целевую машину из группы:
* [Docker](https://docs.primo-rpa.ru/primo-rpa/primo-rpa-ai-server/installing/installation-docker)
