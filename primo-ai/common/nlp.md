# Компонент AI Текст

AI Текст — программный компонент для работы с текстом на естественном языке. Компонент содержит большие языковые модели (Large Language Models, LLM) для решения различных задач в области обработки естественного языка.  

Примеры задач:
* Сортировка писем из общего ящика организации.
* Создание вакансий с указанными параметрами.
* Поиск данных в тексте договора: суммы, даты, предмета, сторон.
* Суммирование ключевых выводов из длинного текста заявки, договора или резюме.

## Навыки LLM-моделей

Чтобы модель решила поставленную задачу, она должна обладать необходимым навыком по обработке входного текста. Модель может обладать одним или сразу несколькими навыками, в зависимости от ваших задач.

Доступные навыки:
* Экстракция — модель извлекает из входного текста информацию по заданным ключам поиска.
* Классификация — модель относит входной текст к одному из известных классов.
* Суммаризация — модель кратко излагает текст с акцентом на указанные темы. 
* Генерация — модель создает текст по заданным параметрам.

## Преимущества компонента AI Текст

Модели не требуют дополнительного обучения — процесс ввода в эксплуатацию состоит из конфигурации и запуска модели.

С моделями можно работать из закрытого контура — таким образом, вы можете защитить чувствительные корпоративные данные из входного текста.

Вы можете протестировать различные сценарии использования до ввода модели в эксплуатацию — в сервис встроен удобный UI-инструмент для отправки тестовых запросов.

Улучшать обработку запросов модели можно с помощью файла контекста (json), где можно прописать примеры корректных ответов на однотипные запросы.

Для использования модели роботами команда Primo RPA обновила пакет Primo.AI.Server — теперь в него входят элементы для отправки асинхронных запросов по обработке текста.

Для использования модели через API вы можете ознакомиться со [спецификацией](https://disk.primo-rpa.ru/index.php/s/t9BHBjR6PP06Yax?path=%2FRelease%2FAI%20Server%2Fapi), которая описана по стандарту Open API.

Горизонтально масштабировать работу с моделями можно за счет использования нескольких целевых машин, на которых модели будут запускаться.

При получении ответов от моделей не взимается дополнительная плата за токены — достаточно лицензии на сервер и целевые машины с компонентом AI Текст.

## Порядок работы с LLM-моделью

Работа с моделью состоит из следующих ключевых этапов:
1. Настройка и запуск модели на целевой машине — выполняется на стороне AI Server.
2. Тестирование поведения модели — выполняется на стороне AI Server.
3. Использование модели роботами или с помощью API-запросов.

### Этап 1 — Конфигурация и запуск модели

Для работы с моделью в AI Server потребуется создать проект с типом NLP-задачи. После создания проекта станет доступна единая страница для конфигурации и запуска модели.

Чтобы сконфигурировать модель, потребуется указать:
* технические параметры целевых машин, на которой планируется запускать модель;
* базовую модель — входит в поставку AI Server;
* выбрать навыки, которыми должна обладать модель.

С каждым навыком модели проассоциирован ключ маршрутизации — с его помощью сервер будет понимать, какой модели требуется направить ваш запрос. Ключи маршрутизации создаются заранее администратором и затем выбираются на странице конфигурации под каждый навык.

Для запуска модели потребуется выбрать одну или несколько целевых машин, которые подходят под указанные технические характеристики. Каждая машина должна обладать лицензией агента для успешного запуска модели. 

### Этап 2 — Тестирование модели

Проверить различные сценарии использования вы можете на странице **Тестирование**. Это позволит увидеть варианты ответов модели и скорректировать их до ввода модели в эксплуатацию.

Изменить поведение модели вы можете с помощью параметров вариативности ответа, а также с помощью файла контекста. 

Вариативность ответа может быть ниже для задач извлечения данных или выше — для задач создания текста. Все зависит от цели использования.

Файл контекста — это файл в формате json, где вы можете прописать возможные запросы, примеры ключей поиска и корректные ответы на подобные запросы. С его помощью модель будет понимать ожидамое поведение и подстраиваться под него.


### Этап 3 — Использование модели

Для использования моделей роботами требуется разработать RPA-проект в Primo RPA Studio. Проекты для взаимодействия с AI Server разрабатываются с помощью NuGet-пакета Primo.AI.Server. В него входят элементы:
* Создать запрос NLP — отправляет асинхронный запрос к Server AI для обработки текста на естественном языке.
* Получить результат NLP — получает результат обработки текста по идентификатору запроса.

При создании запроса потребуется указать не только входной текст, но и ключ маршрутизации — чтобы сервер правильно выбрал модель для обработки запроса. Также вы можете менять поведение модели под каждый запрос, используя собственные файлы контекста, параметры вариативности и длины ответов.

Для использования модели посредством API, изучите [спецификацию](https://disk.primo-rpa.ru/index.php/s/t9BHBjR6PP06Yax?path=%2FRelease%2FAI%20Server%2Fapi).









